import os
import csv
import json
import sys
import re
from pathlib import Path
from datetime import datetime

def tokenize_filename(filename):
    normalized = re.sub(r'[\./]', ' ', filename) # Replace '/' and '.' with spaces, then split by whitespace
    tokens = normalized.split()
    return set(token.lower() for token in tokens if token)

def jaccard_similarity(set1, set2):
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union if union > 0 else 0

def find_most_similar_file(target_file, file_list):
    target_tokens = tokenize_filename(target_file)
    similarity_scores = []
    for filename in file_list:
        file_tokens = tokenize_filename(filename)
        similarity = jaccard_similarity(target_tokens, file_tokens)
        similarity_scores.append((filename, similarity))
    
    similarity_scores.sort(key=lambda x: x[1], reverse=True)
    
    if similarity_scores:
        most_similar, score = similarity_scores[0]
        return most_similar, score
    else:
        return None, 0

def parse_json(json_data):
    try:
        data = json.loads(json_data)
        bug_report_analysis = data.get("analysis_of_the_bug_report", "")
        results = []
        for item in data["ranked_list"]:
            file_name = item.get("file", "")
            justification = item.get("justification", "")
            results.append((file_name, justification))        
        
        return bug_report_analysis, results
    except json.JSONDecodeError as e:
        print("Failed to parse JSON:", e)
        return "",[]
    except KeyError as e:
        print("Missing expected key:", e)
        return "",[]

def extract_filename(full_path):
    if not full_path.endswith(".py"):
        full_path = full_path + ".py"

    base_name = os.path.basename(full_path)
    name, ext = os.path.splitext(base_name)
    return name + ext

def get_suspicious_files(project, bug_id, data):
    suspicious_files = []
    json_file = project + '_bug_data/' + bug_id + '_filewise_method_data.json'
    
    with open(json_file, 'r') as current_file:
        file_wise_method_data = json.load(current_file)

    seen_filenames = set()
    bug_report_analysis, results = parse_json(data)
    for suspicious_filename, justification in results:
        if suspicious_filename in seen_filenames:
            continue
        seen_filenames.add(suspicious_filename)
        
        found = False
        for current_file in file_wise_method_data:
            current_filepath = current_file.get("filepath")
            if current_filepath == suspicious_filename:
                suspicious_files.append({
                    'file': current_filepath,
                    'justification': justification
                })
                found = True
                break
        
        if not found:
            partial_matches = []
            for current_file in file_wise_method_data:
                current_filename = current_file.get("filename")
                if current_filename == extract_filename(suspicious_filename):
                    current_filepath = current_file.get("filepath")
                    partial_matches.append(current_filepath)
            most_similar_file, similarity_score = find_most_similar_file(suspicious_filename, partial_matches)

            if most_similar_file:
                suspicious_files.append({
                    'file': most_similar_file,
                    'justification': justification
                })
                print(suspicious_filename, most_similar_file)
    suspicious_files_json = json.dumps({
        'ranked_list': suspicious_files
    })

    return bug_report_analysis, suspicious_files_json

def ensure_list(x):
    if isinstance(x, str):
        import ast
        return ast.literal_eval(x)
    return x

def process_bug_results(project, csv_path):
    bug_results = {}
    with open(csv_path, newline='', encoding='utf-8', errors='ignore') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            bug_id = row['bug_id']
            try:
                bug_report_analysis, suspicious_files = get_suspicious_files(project, row['bug_id'], row['suspicious_files'])
                fixed_files = ensure_list(row['fixed_files'])
                
                bug_results[bug_id] = {
                    'bug_report_analysis': bug_report_analysis,
                    'suspicious_files': suspicious_files,
                    'fixed_files': fixed_files
                }
            except Exception as e:
                    print(e)
                
    return bug_results

def prepare_final_ranked_list(project, csv_path):
    bug_results = process_bug_results(project, csv_path)
    output_csv = project + '_final_ranked_output.csv'

    with open(output_csv, 'w', newline='', encoding='utf-8') as outfile:
        writer = csv.writer(outfile)
        writer.writerow(['bug_id', 'bug_report_analysis', 'suspicious_files', 'fixed_files'])

        for bug_id, result in bug_results.items():
            analysis = result['bug_report_analysis']
            suspicious_files_json = result['suspicious_files']
            fixed_files = str(result['fixed_files'])
            writer.writerow([bug_id, analysis, suspicious_files_json, fixed_files])

    print(f"Final results written to: {output_csv}")


if __name__ == "__main__":
    # Usage:
    #   python script.py <root_dir>

    root_dir = sys.argv[1]
    start_time = datetime.now()

    input_csvs = []
    for dirpath, _, filenames in os.walk(root_dir):
        for fn in filenames:
            if fn.endswith('-ranking-using-function-call.csv'):
                csv_path = os.path.join(dirpath, fn)
                abs_path = (Path(dirpath) / fn).resolve()
                project = os.path.relpath(abs_path, root_dir)
                project = project.replace('-ranking-using-function-call.csv', '')
                input_csvs.append((csv_path, project))
                # print(csv_path, project)
    if not input_csvs:
        print(f"No ranking CSVs found under {root_dir}")
        sys.exit(1)

    print(f"Found {len(input_csvs)} CSV file(s).")

    for csv_path, project in input_csvs:
        print(f"Processing: {project}")
        prepare_final_ranked_list(project,csv_path)

    end_time = datetime.now()
    print("Total time:", end_time - start_time)